"""æŒä¹…åŒ–è°ƒåº¦å™¨ - è§£è€¦æŒä¹…åŒ–é€»è¾‘.

P1 ä»»åŠ¡ï¼šå°† StateMachineWorker ä¸­çš„æŒä¹…åŒ–é€»è¾‘ç§»åˆ°ç‹¬ç«‹çš„è°ƒåº¦å™¨ä¸­
"""

import os
import pickle
import shutil
import threading
from abc import ABC, abstractmethod
from datetime import datetime
from typing import Any, Optional

from zoo_framework.utils import FileUtils, LogUtils


class PersistenceStrategy(ABC):
    """æŒä¹…åŒ–ç­–ç•¥åŸºç±».

    å®šä¹‰æŒä¹…åŒ–çš„æ¥å£ï¼Œæ”¯æŒä¸åŒçš„æŒä¹…åŒ–å®ç°ã€‚
    """

    @abstractmethod
    def save(self, data: Any, filepath: str) -> bool:
        """ä¿å­˜æ•°æ®."""
        pass

    @abstractmethod
    def load(self, filepath: str) -> Optional[Any]:
        """åŠ è½½æ•°æ®."""
        pass

    @abstractmethod
    def validate(self, filepath: str) -> bool:
        """éªŒè¯æ•°æ®å®Œæ•´æ€§."""
        pass


class PicklePersistenceStrategy(PersistenceStrategy):
    """Pickle æŒä¹…åŒ–ç­–ç•¥."""

    def save(self, data: Any, filepath: str) -> bool:
        """ä½¿ç”¨ Pickle ä¿å­˜æ•°æ®."""
        try:
            # å†™å…¥ä¸´æ—¶æ–‡ä»¶
            temp_path = filepath + ".tmp"
            with open(temp_path, "wb") as f:
                pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)

            # åŸå­æ€§æ›¿æ¢
            if os.path.exists(filepath):
                os.replace(temp_path, filepath)
            else:
                os.rename(temp_path, filepath)

            return True
        except Exception as e:
            LogUtils.error(f"âŒ Pickle save failed: {e}")
            return False

    def load(self, filepath: str) -> Optional[Any]:
        """ä½¿ç”¨ Pickle åŠ è½½æ•°æ®."""
        try:
            with open(filepath, "rb") as f:
                return pickle.load(f)
        except Exception as e:
            LogUtils.error(f"âŒ Pickle load failed: {e}")
            return None

    def validate(self, filepath: str) -> bool:
        """éªŒè¯ Pickle æ–‡ä»¶å®Œæ•´æ€§."""
        try:
            with open(filepath, "rb") as f:
                content = f.read()
                if not content:
                    return False
                f.seek(0)
                pickle.load(f)
                return True
        except Exception:
            return False


class FileChecksumValidator:
    """æ–‡ä»¶æ ¡éªŒå’ŒéªŒè¯å™¨.

    P1 ä»»åŠ¡ï¼šå®ç°æ–‡ä»¶æ ¡éªŒåŠŸèƒ½
    """

    @staticmethod
    def calculate_checksum(filepath: str) -> str:
        """è®¡ç®—æ–‡ä»¶æ ¡éªŒå’Œï¼ˆMD5ï¼‰.

        Args:
            filepath: æ–‡ä»¶è·¯å¾„

        Returns:
            MD5 æ ¡éªŒå’Œå­—ç¬¦ä¸²
        """
        import hashlib

        hash_md5 = hashlib.md5()
        with open(filepath, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_md5.update(chunk)
        return hash_md5.hexdigest()

    @staticmethod
    def verify_checksum(filepath: str, expected_checksum: str) -> bool:
        """éªŒè¯æ–‡ä»¶æ ¡éªŒå’Œ.

        Args:
            filepath: æ–‡ä»¶è·¯å¾„
            expected_checksum: æœŸæœ›çš„æ ¡éªŒå’Œ

        Returns:
            æ ¡éªŒæ˜¯å¦é€šè¿‡
        """
        actual_checksum = FileChecksumValidator.calculate_checksum(filepath)
        return actual_checksum == expected_checksum

    @staticmethod
    def save_checksum(filepath: str, checksum: str) -> None:
        """ä¿å­˜æ ¡éªŒå’Œåˆ°æ–‡ä»¶.

        Args:
            filepath: åŸæ–‡ä»¶è·¯å¾„
            checksum: æ ¡éªŒå’Œå€¼
        """
        checksum_path = filepath + ".checksum"
        with open(checksum_path, "w") as f:
            f.write(checksum)

    @staticmethod
    def load_checksum(filepath: str) -> Optional[str]:
        """ä»æ–‡ä»¶åŠ è½½æ ¡éªŒå’Œ.

        Args:
            filepath: åŸæ–‡ä»¶è·¯å¾„

        Returns:
            æ ¡éªŒå’Œå€¼ï¼Œå¦‚æœä¸å­˜åœ¨è¿”å› None
        """
        checksum_path = filepath + ".checksum"
        if not os.path.exists(checksum_path):
            return None

        with open(checksum_path) as f:
            return f.read().strip()


class BackupManager:
    """å¤‡ä»½ç®¡ç†å™¨.

    P1 ä»»åŠ¡ï¼šå®ç°æ–‡ä»¶å¤‡ä»½å’Œåˆ‡ç‰‡åŠŸèƒ½
    """

    def __init__(self, backup_dir: str = "backups", max_backups: int = 5):
        self.backup_dir = backup_dir
        self.max_backups = max_backups

    def create_backup(self, filepath: str) -> Optional[str]:
        """åˆ›å»ºæ–‡ä»¶å¤‡ä»½.

        Args:
            filepath: åŸæ–‡ä»¶è·¯å¾„

        Returns:
            å¤‡ä»½æ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥è¿”å› None
        """
        if not os.path.exists(filepath):
            return None

        # åˆ›å»ºå¤‡ä»½ç›®å½•
        file_dir = os.path.dirname(filepath)
        backup_dir = os.path.join(file_dir, self.backup_dir)
        os.makedirs(backup_dir, exist_ok=True)

        # ç”Ÿæˆå¤‡ä»½æ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = os.path.basename(filepath)
        backup_path = os.path.join(backup_dir, f"{filename}.{timestamp}.bak")

        try:
            shutil.copy2(filepath, backup_path)

            # ä¿å­˜æ ¡éªŒå’Œ
            checksum = FileChecksumValidator.calculate_checksum(filepath)
            FileChecksumValidator.save_checksum(backup_path, checksum)

            LogUtils.info(f"ğŸ“¦ Backup created: {backup_path}")

            # æ¸…ç†æ—§å¤‡ä»½
            self._cleanup_old_backups(backup_dir, filename)

            return backup_path
        except Exception as e:
            LogUtils.error(f"âŒ Backup failed: {e}")
            return None

    def restore_backup(self, filepath: str) -> bool:
        """ä»å¤‡ä»½æ¢å¤æ–‡ä»¶.

        Args:
            filepath: åŸæ–‡ä»¶è·¯å¾„

        Returns:
            æ˜¯å¦æ¢å¤æˆåŠŸ
        """
        file_dir = os.path.dirname(filepath)
        backup_dir = os.path.join(file_dir, self.backup_dir)

        if not os.path.exists(backup_dir):
            LogUtils.warning("âš ï¸ Backup directory not found")
            return False

        filename = os.path.basename(filepath)
        backup_files = []

        # æŸ¥æ‰¾å¤‡ä»½æ–‡ä»¶
        for f in os.listdir(backup_dir):
            if f.startswith(filename) and f.endswith(".bak"):
                backup_files.append(os.path.join(backup_dir, f))

        if not backup_files:
            LogUtils.warning("âš ï¸ No backup files found")
            return False

        # æŒ‰æ—¶é—´æ’åºï¼Œé€‰æ‹©æœ€æ–°çš„
        backup_files.sort(reverse=True)
        latest_backup = backup_files[0]

        # éªŒè¯å¤‡ä»½å®Œæ•´æ€§
        expected_checksum = FileChecksumValidator.load_checksum(latest_backup)
        if expected_checksum:
            if not FileChecksumValidator.verify_checksum(latest_backup, expected_checksum):
                LogUtils.error("âŒ Backup file corrupted")
                return False

        try:
            shutil.copy2(latest_backup, filepath)
            LogUtils.info(f"âœ… Restored from backup: {latest_backup}")
            return True
        except Exception as e:
            LogUtils.error(f"âŒ Restore failed: {e}")
            return False

    def _cleanup_old_backups(self, backup_dir: str, filename: str) -> None:
        """æ¸…ç†æ—§å¤‡ä»½æ–‡ä»¶.

        Args:
            backup_dir: å¤‡ä»½ç›®å½•
            filename: åŸæ–‡ä»¶å
        """
        backup_files = []

        for f in os.listdir(backup_dir):
            if f.startswith(filename) and f.endswith(".bak"):
                filepath = os.path.join(backup_dir, f)
                backup_files.append((filepath, os.path.getmtime(filepath)))

        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åº
        backup_files.sort(key=lambda x: x[1], reverse=True)

        # åˆ é™¤æ—§å¤‡ä»½
        for old_file, _ in backup_files[self.max_backups :]:
            try:
                os.remove(old_file)
                # åŒæ—¶åˆ é™¤æ ¡éªŒå’Œæ–‡ä»¶
                checksum_file = old_file + ".checksum"
                if os.path.exists(checksum_file):
                    os.remove(checksum_file)
                LogUtils.debug(f"ğŸ—‘ï¸ Old backup removed: {old_file}")
            except Exception as e:
                LogUtils.warning(f"âš ï¸ Failed to remove old backup: {e}")


class PersistenceScheduler:
    """æŒä¹…åŒ–è°ƒåº¦å™¨.

    P1 ä»»åŠ¡ï¼šè§£è€¦æŒä¹…åŒ–é€»è¾‘ï¼Œç”±è°ƒåº¦å™¨å†³å®šä½•æ—¶æŒä¹…åŒ–

    èŒè´£ï¼š
    - ç®¡ç†æŒä¹…åŒ–æ—¶æœº
    - æ‰§è¡Œæ•°æ®ä¿å­˜å’ŒåŠ è½½
    - å¤„ç†å¤‡ä»½å’Œæ¢å¤
    - éªŒè¯æ•°æ®å®Œæ•´æ€§
    """

    def __init__(
        self,
        filepath: str,
        strategy: Optional[PersistenceStrategy] = None,
        auto_save_interval: int = 60,  # è‡ªåŠ¨ä¿å­˜é—´éš”ï¼ˆç§’ï¼‰
        enable_backup: bool = True,
        max_backups: int = 5,
    ):
        self.filepath = filepath
        self.strategy = strategy or PicklePersistenceStrategy()
        self.auto_save_interval = auto_save_interval
        self.enable_backup = enable_backup

        self._backup_manager = BackupManager(max_backups=max_backups) if enable_backup else None
        self._file_lock = threading.RLock()
        self._data: Optional[Any] = None
        self._dirty = False  # æ•°æ®æ˜¯å¦è¢«ä¿®æ”¹
        self._last_save_time = 0
        self._running = False
        self._scheduler_thread: Optional[threading.Thread] = None

    def start(self) -> None:
        """å¯åŠ¨æŒä¹…åŒ–è°ƒåº¦å™¨."""
        if self._running:
            return

        self._running = True
        if self.auto_save_interval > 0:
            self._scheduler_thread = threading.Thread(target=self._scheduler_loop)
            self._scheduler_thread.daemon = True
            self._scheduler_thread.start()

        LogUtils.info("âœ… Persistence scheduler started")

    def stop(self) -> None:
        """åœæ­¢æŒä¹…åŒ–è°ƒåº¦å™¨."""
        self._running = False

        # æœ€åä¿å­˜ä¸€æ¬¡
        if self._dirty:
            self.save(force=True)

        if self._scheduler_thread:
            self._scheduler_thread.join(timeout=5)

        LogUtils.info("ğŸ›‘ Persistence scheduler stopped")

    def _scheduler_loop(self) -> None:
        """è°ƒåº¦å¾ªç¯."""
        import time

        while self._running:
            try:
                time.sleep(self.auto_save_interval)
                if self._dirty:
                    self.save()
            except Exception as e:
                LogUtils.error(f"âŒ Scheduler error: {e}")

    def load(self) -> Optional[Any]:
        """åŠ è½½æ•°æ®.

        Returns:
            åŠ è½½çš„æ•°æ®ï¼Œå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨æˆ–æŸåè¿”å› None
        """
        with self._file_lock:
            if not FileUtils.file_exists(self.filepath):
                LogUtils.info("ğŸ“ No persistence file found")
                return None

            # éªŒè¯æ–‡ä»¶å®Œæ•´æ€§
            if not self.strategy.validate(self.filepath):
                LogUtils.error("âŒ Persistence file corrupted, trying backup")
                if self._backup_manager:
                    if self._backup_manager.restore_backup(self.filepath):
                        LogUtils.info("âœ… Restored from backup")
                    else:
                        return None
                else:
                    return None

            # åŠ è½½æ•°æ®
            data = self.strategy.load(self.filepath)
            if data is not None:
                self._data = data
                LogUtils.info("âœ… Data loaded successfully")

            return data

    def save(self, force: bool = False) -> bool:
        """ä¿å­˜æ•°æ®.

        Args:
            force: æ˜¯å¦å¼ºåˆ¶ä¿å­˜ï¼ˆå¿½ç•¥ dirty æ ‡è®°ï¼‰

        Returns:
            æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        with self._file_lock:
            if not force and not self._dirty:
                return True

            if self._data is None:
                return False

            # åˆ›å»ºå¤‡ä»½
            if self.enable_backup and self._backup_manager:
                self._backup_manager.create_backup(self.filepath)

            # ä¿å­˜æ•°æ®
            success = self.strategy.save(self._data, self.filepath)

            if success:
                self._dirty = False
                self._last_save_time = datetime.now().timestamp()

                # ä¿å­˜æ ¡éªŒå’Œ
                checksum = FileChecksumValidator.calculate_checksum(self.filepath)
                FileChecksumValidator.save_checksum(self.filepath, checksum)

                LogUtils.debug("ğŸ’¾ Data saved successfully")
            else:
                LogUtils.error("âŒ Failed to save data")

            return success

    def mark_dirty(self) -> None:
        """æ ‡è®°æ•°æ®ä¸ºå·²ä¿®æ”¹."""
        self._dirty = True

    def update_data(self, data: Any, auto_save: bool = False) -> None:
        """æ›´æ–°æ•°æ®.

        Args:
            data: æ–°æ•°æ®
            auto_save: æ˜¯å¦ç«‹å³ä¿å­˜
        """
        self._data = data
        self._dirty = True

        if auto_save:
            self.save()

    def get_data(self) -> Optional[Any]:
        """è·å–å½“å‰æ•°æ®."""
        return self._data

    def is_dirty(self) -> bool:
        """æ£€æŸ¥æ•°æ®æ˜¯å¦è¢«ä¿®æ”¹."""
        return self._dirty


# å¯¼å‡ºå…¬å…± API
__all__ = [
    "BackupManager",
    "FileChecksumValidator",
    "PersistenceScheduler",
    "PersistenceStrategy",
    "PicklePersistenceStrategy",
]
