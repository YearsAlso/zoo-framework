# ğŸ› è°ƒè¯•æŒ‡å—

æœ¬æ–‡æ¡£æä¾› Zoo Framework çš„å¸¸è§é—®é¢˜å’Œè°ƒè¯•æŠ€å·§ã€‚

---

## ğŸ”§ å¸¸ç”¨è°ƒè¯•æ–¹æ³•

### 1. å¼€å¯ DEBUG æ—¥å¿—

```python
import logging

# è®¾ç½®æ—¥å¿—çº§åˆ«
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

# æˆ–è€…åªè®¾ç½®æ¡†æ¶æ—¥å¿—
logging.getLogger('zoo_framework').setLevel(logging.DEBUG)
```

### 2. ä½¿ç”¨ç»“æ„åŒ–æ—¥å¿—

```python
from zoo_framework.utils.structured_log import get_logger

logger = get_logger("MyWorker")
logger.bind(worker_id="123", task="process")

# è®°å½•æ—¥å¿—
logger.info("ä»»åŠ¡å¼€å§‹", priority=10)
logger.error("å¤„ç†å¤±è´¥", error="timeout", retry_count=3)

# è®°å½•æŒ‡æ ‡
logger.metric("execution_time", 0.5, "seconds")
```

è¾“å‡ºç¤ºä¾‹ï¼š
```json
{"event": "ä»»åŠ¡å¼€å§‹", "worker_id": "123", "task": "process", "priority": 10, "timestamp": "2024-01-15T10:30:00Z"}
```

### 3. ä½¿ç”¨ PDB è°ƒè¯•

```python
def _execute(self):
    import pdb; pdb.set_trace()
    
    # å¸¸ç”¨å‘½ä»¤ï¼š
    # n - ä¸‹ä¸€è¡Œ
    # s - è¿›å…¥å‡½æ•°
    # c - ç»§ç»­æ‰§è¡Œ
    # p variable - æ‰“å°å˜é‡
    # l - æ˜¾ç¤ºä»£ç 
    
    result = self.process_data()
    return result
```

### 4. Worker æ€§èƒ½åˆ†æ

```python
import time
from zoo_framework.utils import LogUtils

class ProfiledWorker(BaseWorker):
    def __init__(self):
        super().__init__({"name": "ProfiledWorker"})
        self.execution_times = []
    
    def _execute(self):
        start = time.perf_counter()
        
        # ä¸šåŠ¡é€»è¾‘
        self.do_work()
        
        duration = time.perf_counter() - start
        self.execution_times.append(duration)
        
        # æ‰“å°ç»Ÿè®¡
        if len(self.execution_times) % 10 == 0:
            avg = sum(self.execution_times) / len(self.execution_times)
            LogUtils.info(f"å¹³å‡æ‰§è¡Œæ—¶é—´: {avg:.3f}s")
```

---

## ğŸ› å¸¸è§é—®é¢˜

### Q1: Worker ä¸æ‰§è¡Œ

**ç—‡çŠ¶**ï¼šWorker åˆ›å»ºåæ²¡æœ‰æ‰§è¡Œ `_execute` æ–¹æ³•ã€‚

**æ’æŸ¥æ­¥éª¤**ï¼š

```python
# 1. æ£€æŸ¥ Worker æ˜¯å¦æ³¨å†Œ
from zoo_framework.core.aop import worker_register
print(worker_register.get_all_worker())  # åº”è¯¥åŒ…å«ä½ çš„ Worker

# 2. æ£€æŸ¥ Master æ˜¯å¦å¯åŠ¨
master = Master()
# ç¡®ä¿è°ƒç”¨äº† run()
master.run()  # è¿™ä¼šé˜»å¡

# 3. æ£€æŸ¥ is_loop è®¾ç½®
class MyWorker(BaseWorker):
    def __init__(self):
        super().__init__({
            "is_loop": True,  # ç¡®ä¿è®¾ç½®ä¸º True
            "delay_time": 1.0,
            "name": "MyWorker"
        })
```

### Q2: çº¿ç¨‹å®‰å…¨é—®é¢˜

**ç—‡çŠ¶**ï¼šæ•°æ®ä¸ä¸€è‡´ã€ç«æ€æ¡ä»¶ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š

```python
from zoo_framework.core.aop import cage
from threading import RLock

@cage
class SafeWorker(BaseWorker):
    def __init__(self):
        super().__init__({"name": "SafeWorker"})
        self._lock = RLock()
        self.counter = 0
    
    def _execute(self):
        with self._lock:
            # ä¸´ç•ŒåŒºä»£ç 
            self.counter += 1
            print(f"Counter: {self.counter}")
```

### Q3: å†…å­˜æ³„æ¼

**ç—‡çŠ¶**ï¼šå†…å­˜æŒç»­å¢é•¿ï¼Œæœ€ç»ˆ OOMã€‚

**å¸¸è§åŸå› å’Œè§£å†³**ï¼š

```python
# 1. è§‚å¯Ÿè€…æœªæ­£ç¡®ç§»é™¤
class MyWorker(BaseWorker):
    def __init__(self):
        super().__init__()
        self._effects = []
    
    def observe(self, key, callback):
        from zoo_framework.statemachine import StateMachineManager
        sm = StateMachineManager()
        sm.observe_state(key, callback)
        self._effects.append((key, callback))
    
    def _destroy(self, result):
        # æ¸…ç†è§‚å¯Ÿè€…
        from zoo_framework.statemachine import StateMachineManager
        sm = StateMachineManager()
        for key, callback in self._effects:
            sm.unobserve_state(key, callback)

# 2. å¾ªç¯å¼•ç”¨
import weakref

class Node:
    def __init__(self):
        # âŒ é”™è¯¯ï¼šå¼ºå¼•ç”¨
        # self.parent = None
        # self.children = []
        
        # âœ… æ­£ç¡®ï¼šä½¿ç”¨å¼±å¼•ç”¨
        self.parent = None
        self.children = weakref.WeakSet()

# 3. ç¼“å­˜æ— é™åˆ¶å¢é•¿
class CachedWorker(BaseWorker):
    def __init__(self):
        super().__init__()
        self._cache = {}
        self._max_cache_size = 1000
    
    def add_to_cache(self, key, value):
        if len(self._cache) >= self._max_cache_size:
            # æ¸…ç†æ—§æ•°æ®
            oldest_key = next(iter(self._cache))
            del self._cache[oldest_key]
        self._cache[key] = value
```

### Q4: çŠ¶æ€æœºæŒä¹…åŒ–å¤±è´¥

**ç—‡çŠ¶**ï¼šçŠ¶æ€æ— æ³•ä¿å­˜æˆ–æ¢å¤ã€‚

**æ’æŸ¥æ­¥éª¤**ï¼š

```python
# 1. æ£€æŸ¥æ–‡ä»¶æƒé™
import os
state_file = "state.pkl"
print(f"å¯å†™: {os.access(os.path.dirname(state_file) or '.', os.W_OK)}")

# 2. æ£€æŸ¥æŒä¹…åŒ–è°ƒåº¦å™¨
from zoo_framework.core.persistence_scheduler import PersistenceScheduler

scheduler = PersistenceScheduler("state.pkl")
scheduler.start()

# æ ‡è®°æ•°æ®ä¸ºè„ï¼ˆéœ€è¦ä¿å­˜ï¼‰
scheduler.mark_dirty()

# å¼ºåˆ¶ä¿å­˜
scheduler.save(force=True)

# æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
print(f"æ–‡ä»¶å­˜åœ¨: {os.path.exists('state.pkl')}")

# 3. æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
if scheduler.strategy.validate("state.pkl"):
    data = scheduler.load()
    print(f"åŠ è½½æˆåŠŸ: {data}")
```

### Q5: äº‹ä»¶æœªè§¦å‘

**ç—‡çŠ¶**ï¼šå‘é€äº‹ä»¶ä½† Worker æœªæ”¶åˆ°ã€‚

**æ’æŸ¥æ­¥éª¤**ï¼š

```python
# 1. æ£€æŸ¥é€šé“æ˜¯å¦æ­£ç¡®
from zoo_framework.reactor.event_reactor_req import ChannelType

# å‘é€äº‹ä»¶
EventReactorManager.dispatch(
    topic="my.event",
    content={"data": "test"},
    channel=ChannelType.BUSINESS.value  # ç¡®ä¿é€šé“åŒ¹é…
)

# 2. æ£€æŸ¥å“åº”å™¨æ³¨å†Œ
reactor = EventReactorManager.get_reactor("my.event")
print(f"å“åº”å™¨: {reactor}")

# 3. æ£€æŸ¥é€šé“æƒé™
from zoo_framework.reactor.event_reactor_req import get_channel_manager

channel_manager = get_channel_manager()
can_handle = channel_manager.can_handle_event(
    reactor_name="my_reactor",
    event=EventReactorReq("my.event", {}, "my_reactor", ChannelType.BUSINESS.value)
)
print(f"å¯ä»¥å¤„ç†: {can_handle}")
```

### Q6: å¼‚æ­¥ Worker é—®é¢˜

**ç—‡çŠ¶**ï¼šå¼‚æ­¥ Worker ä¸æ‰§è¡Œæˆ–æŠ¥é”™ã€‚

```python
# 1. ç¡®ä¿æ­£ç¡®ä½¿ç”¨ async/await
class MyAsyncWorker(AsyncWorker):
    async def async_execute(self):
        # âœ… æ­£ç¡®ï¼šä½¿ç”¨ await
        result = await self.async_operation()
        return result
        
        # âŒ é”™è¯¯ï¼šæ²¡æœ‰ await
        # result = self.async_operation()

# 2. æ£€æŸ¥äº‹ä»¶å¾ªç¯
import asyncio

try:
    loop = asyncio.get_running_loop()
    print(f"å·²æœ‰äº‹ä»¶å¾ªç¯: {loop}")
except RuntimeError:
    print("æ²¡æœ‰è¿è¡Œçš„äº‹ä»¶å¾ªç¯")

# 3. è¿è¡Œå¼‚æ­¥ Worker
worker = MyAsyncWorker()

# æ–¹å¼1ï¼šåŒæ­¥è¿è¡Œï¼ˆé˜»å¡ï¼‰
result = worker.execute()

# æ–¹å¼2ï¼šåå°è¿è¡Œï¼ˆéé˜»å¡ï¼‰
task = worker.run_in_background()
# ç¨åè·å–ç»“æœ
if task.done():
    result = task.result()
```

---

## ğŸ“Š æ€§èƒ½è°ƒä¼˜

### 1. ç›‘æ§ Worker æ€§èƒ½

```python
from zoo_framework.core import Master

master = Master()

# è·å–å¥åº·æŠ¥å‘Š
report = master.get_health_report()
for worker_name, health in report.items():
    print(f"Worker: {worker_name}")
    print(f"  çŠ¶æ€: {health['status']}")
    print(f"  å¥åº·è¯„åˆ†: {health['health_score']}")
    print(f"  æ‰§è¡Œæ¬¡æ•°: {health['execute_count']}")
    print(f"  é”™è¯¯ç‡: {health['error_rate']:.2%}")
    print(f"  å¹³å‡æ‰§è¡Œæ—¶é—´: {health['avg_execute_time']:.3f}s")
```

### 2. ä¼˜åŒ– delay_time

```python
# é«˜é¢‘ä»»åŠ¡ï¼ˆæ•°æ®å¤„ç†ï¼‰
class FastWorker(BaseWorker):
    def __init__(self):
        super().__init__({
            "is_loop": True,
            "delay_time": 0.01,  # 10ms
            "name": "FastWorker"
        })

# ä¸­é¢‘ä»»åŠ¡ï¼ˆçŠ¶æ€æ£€æŸ¥ï¼‰
class MediumWorker(BaseWorker):
    def __init__(self):
        super().__init__({
            "is_loop": True,
            "delay_time": 1.0,   # 1s
            "name": "MediumWorker"
        })

# ä½é¢‘ä»»åŠ¡ï¼ˆæŠ¥è¡¨ç”Ÿæˆï¼‰
class SlowWorker(BaseWorker):
    def __init__(self):
        super().__init__({
            "is_loop": True,
            "delay_time": 3600,  # 1 hour
            "name": "SlowWorker"
        })
```

### 3. ä½¿ç”¨ Worker æ± 

```python
from zoo_framework.workers import AsyncWorkerPool

# åˆ›å»º Worker æ± 
pool = AsyncWorkerPool(max_workers=10)

# æ‰¹é‡æäº¤ä»»åŠ¡
items = [1, 2, 3, 4, 5]
results = await pool.map(worker, items)
```

---

## ğŸ” è¯Šæ–­å·¥å…·

### 1. æŸ¥çœ‹çº¿ç¨‹çŠ¶æ€

```python
import threading

def print_thread_info():
    print(f"å½“å‰çº¿ç¨‹: {threading.current_thread().name}")
    print(f"æ´»è·ƒçº¿ç¨‹æ•°: {threading.active_count()}")
    print("æ‰€æœ‰çº¿ç¨‹:")
    for thread in threading.enumerate():
        print(f"  - {thread.name} (daemon: {thread.daemon})")

print_thread_info()
```

### 2. å†…å­˜åˆ†æ

```python
import tracemalloc

# å¼€å§‹è·Ÿè¸ª
tracemalloc.start()

# æ‰§è¡Œä¸šåŠ¡é€»è¾‘
worker.execute()

# è·å–å†…å­˜å¿«ç…§
snapshot = tracemalloc.take_snapshot()
top_stats = snapshot.statistics('lineno')

print("[Top 10]")
for stat in top_stats[:10]:
    print(stat)
```

### 3. æ€§èƒ½åˆ†æ

```python
import cProfile
import pstats

# åˆ›å»º profiler
profiler = cProfile.Profile()
profiler.enable()

# è¿è¡Œä»£ç 
master.run()

profiler.disable()

# æ‰“å°ç»Ÿè®¡
stats = pstats.Stats(profiler)
stats.sort_stats('cumulative')
stats.print_stats(20)  # å‰20ä¸ª
```

---

## ğŸ†˜ ç´§æ€¥ä¿®å¤

### å¦‚ä½•å®‰å…¨åœæ­¢ Master

```python
import signal
import sys

def graceful_shutdown(signum, frame):
    print("\nğŸ›‘ æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œæ­£åœ¨ä¼˜é›…å…³é—­...")
    master.shutdown()
    sys.exit(0)

# æ³¨å†Œä¿¡å·å¤„ç†
signal.signal(signal.SIGINT, graceful_shutdown)  # Ctrl+C
signal.signal(signal.SIGTERM, graceful_shutdown)

master.run()
```

### æ¸…ç†åƒµå°¸ Worker

```python
def cleanup_workers():
    """æ¸…ç†æœªæ­£ç¡®åœæ­¢çš„ Worker"""
    import threading
    
    for thread in threading.enumerate():
        if thread.name.startswith("Worker-"):
            print(f"æ¸…ç† Worker: {thread.name}")
            # å¼ºåˆ¶åœæ­¢ï¼ˆä¸æ¨èï¼Œä»…ç”¨äºç´§æ€¥æƒ…å†µï¼‰
            # æ›´å¥½çš„æ–¹å¼æ˜¯ä½¿ç”¨ threading.Event

cleanup_workers()
```

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [å¿«é€Ÿå¼€å§‹](DEVELOPMENT.md)
- [æ¶æ„è®¾è®¡](ARCHITECTURE.md)
- [è´¡çŒ®æŒ‡å—](CONTRIBUTING.md)
- [API å‚è€ƒ](API_REFERENCE.md)
